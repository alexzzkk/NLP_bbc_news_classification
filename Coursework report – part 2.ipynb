{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edb7fce7",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "347961d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89d931bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it is required to download en_core_web_sm\n",
    "#spacy.cli.download('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5845cf1f",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ad8786",
   "metadata": {},
   "source": [
    "## Append text data to list\n",
    "Note that data must be in the same directory as this notebook, in the bbc folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a10659c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty list for storing the path which will be used for for-loop and read the text from\n",
    "list_path = []\n",
    "\n",
    "#construct a list that contains all the path for all txt files\n",
    "for i in os.listdir('bbc/'):\n",
    "    # for each path, if the path string contains dot symbol then continue\n",
    "    if i.find('.')!=-1:\n",
    "        continue\n",
    "    else:\n",
    "    # for each txt file in different folders, append its path to the empty list_path\n",
    "        for j in os.listdir(\"bbc/{}\".format(i)):\n",
    "            list_path.append(\"bbc/{}/{}\".format(i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79d7e84c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#exclude the path of each text contains dirty data \n",
    "list_path = list(filter(lambda x:x.find(\"DS_Store\")==-1,list_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af89a3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty list for each class\n",
    "list_business = []\n",
    "list_entertainment = []\n",
    "list_politics = []\n",
    "list_tech = []\n",
    "list_sport = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb37dbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function that will read the text and append the test to the list\n",
    "def append_list(list_name,category):\n",
    "    for i in list_path:\n",
    "        if i.find(category)!=-1:\n",
    "            list_name.append(Path(i).read_text())\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab1c0d7",
   "metadata": {},
   "source": [
    "There is a issue about the pound sterling sign in the 199.txt file in bbc/sport folder. I replaced the orginal pound sterling sign with a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ca296c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each path, apply the append_list function\n",
    "append_list(list_business,\"business\")\n",
    "append_list(list_entertainment,\"entertainment\")\n",
    "append_list(list_politics,\"politics\")\n",
    "append_list(list_tech,\"tech\")\n",
    "append_list(list_sport,\"sport\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24ad20c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2225"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if all files were read\n",
    "len(list_business) + len(list_entertainment) + len(list_politics) + len(list_tech) + len(list_sport)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0b770a",
   "metadata": {},
   "source": [
    "## Create pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eaa065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pandas dataframes for each category, assign label to them.\n",
    "df_business = pd.DataFrame({\"content\":list_business,\n",
    "                            \"label\":0,\n",
    "                            \"label_en\":\"business\"})\n",
    "\n",
    "df_entertainment = pd.DataFrame({\"content\":list_entertainment,\n",
    "                                 \"label\":1,\n",
    "                                 \"label_en\":\"entertainment\"})\n",
    "\n",
    "df_politics = pd.DataFrame({\"content\":list_politics,\n",
    "                            \"label\":2,\n",
    "                            \"label_en\":\"politics\"})\n",
    "\n",
    "df_tech = pd.DataFrame({\"content\":list_tech,\n",
    "                        \"label\":3,\n",
    "                        \"label_en\":\"tech\"})\n",
    "\n",
    "df_sport = pd.DataFrame({\"content\":list_sport,\n",
    "                         \"label\":4,\n",
    "                         \"label_en\":\"sport\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c4a2a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all data into one dataframe\n",
    "frames = [df_business,df_entertainment,df_politics,df_tech,df_sport]\n",
    "dataset = pd.concat(frames)\n",
    "#reset the index and drop the index column\n",
    "dataset_final = dataset.reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8bab2369",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle the dataset\n",
    "dataset_final = shuffle(dataset_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b96d9a",
   "metadata": {},
   "source": [
    "## Tokenization, lemmatization, removing punctuation/stopwords, lowering words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0329158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load en_core_web_sm for further data clearning using spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36785478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(x):\n",
    "    \"\"\"\n",
    "    This function is to remove punctuation/space/determiners/particles/stop words in documents.\n",
    "    Then words will be lemmatized and lowered.\n",
    "    The function returns list of words.\n",
    "    \"\"\"\n",
    "    doc = nlp(x)\n",
    "    return [token.lemma_.lower() for token in doc if token.pos_ not in ('PUNCT','SPACE','DET','PART') and token.is_stop == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54fdf05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map the function to content and then create a column for storing cleaned data\n",
    "dataset_final['tokenization'] = dataset_final['content'].map(data_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb106fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>label_en</th>\n",
       "      <th>tokenization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>Royal couple watch nation's mood\\n\\nPrince Cha...</td>\n",
       "      <td>2</td>\n",
       "      <td>politics</td>\n",
       "      <td>[royal, couple, watch, nation, mood, prince, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>Labour in constituency race row\\n\\nLabour's ch...</td>\n",
       "      <td>2</td>\n",
       "      <td>politics</td>\n",
       "      <td>[labour, constituency, race, row, labour, choi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>Melzer shocks Agassi in San Jose\\n\\nSecond see...</td>\n",
       "      <td>4</td>\n",
       "      <td>sport</td>\n",
       "      <td>[melzer, shock, agassi, san, jose, second, see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>Wright-Phillips to start on right\\n\\nEngland c...</td>\n",
       "      <td>4</td>\n",
       "      <td>sport</td>\n",
       "      <td>[wright, phillips, start, right, england, coac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Making your office work for you\\n\\nOur mission...</td>\n",
       "      <td>0</td>\n",
       "      <td>business</td>\n",
       "      <td>[make, office, work, mission, brighten, work, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  label  label_en  \\\n",
       "975   Royal couple watch nation's mood\\n\\nPrince Cha...      2  politics   \n",
       "1273  Labour in constituency race row\\n\\nLabour's ch...      2  politics   \n",
       "2222  Melzer shocks Agassi in San Jose\\n\\nSecond see...      4     sport   \n",
       "1797  Wright-Phillips to start on right\\n\\nEngland c...      4     sport   \n",
       "362   Making your office work for you\\n\\nOur mission...      0  business   \n",
       "\n",
       "                                           tokenization  \n",
       "975   [royal, couple, watch, nation, mood, prince, c...  \n",
       "1273  [labour, constituency, race, row, labour, choi...  \n",
       "2222  [melzer, shock, agassi, san, jose, second, see...  \n",
       "1797  [wright, phillips, start, right, england, coac...  \n",
       "362   [make, office, work, mission, brighten, work, ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe701d49",
   "metadata": {},
   "source": [
    "## Feature Extraction - Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eeaf9eb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a function will be used to extract the named entity labels for each token.\n",
    "def named_entity(x):\n",
    "    mylist = [token.label_ for token in nlp(x).ents]\n",
    "    return mylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7123a65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract named entity labels for each content\n",
    "dataset_final[\"ner\"] = dataset_final['content'].apply(named_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08d068b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a list contains each type of labels is created.\n",
    "ner_list = dataset_final[\"ner\"].explode().value_counts().reset_index()['ner'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af4bb8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use for-loop to count the occurence of each label for all rows\n",
    "for _ in ner_list:\n",
    "    dataset_final[str(_)] = dataset_final.apply(lambda x: x['ner'].count(_), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "547a15f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>label_en</th>\n",
       "      <th>tokenization</th>\n",
       "      <th>ner</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>ORG</th>\n",
       "      <th>DATE</th>\n",
       "      <th>GPE</th>\n",
       "      <th>CARDINAL</th>\n",
       "      <th>...</th>\n",
       "      <th>PERCENT</th>\n",
       "      <th>LOC</th>\n",
       "      <th>TIME</th>\n",
       "      <th>WORK_OF_ART</th>\n",
       "      <th>EVENT</th>\n",
       "      <th>PRODUCT</th>\n",
       "      <th>FAC</th>\n",
       "      <th>QUANTITY</th>\n",
       "      <th>LAW</th>\n",
       "      <th>LANGUAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>Royal couple watch nation's mood\\n\\nPrince Cha...</td>\n",
       "      <td>2</td>\n",
       "      <td>politics</td>\n",
       "      <td>[royal, couple, watch, nation, mood, prince, c...</td>\n",
       "      <td>[ORG, DATE, PERSON, ORG, FAC, ORG, CARDINAL, C...</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>Labour in constituency race row\\n\\nLabour's ch...</td>\n",
       "      <td>2</td>\n",
       "      <td>politics</td>\n",
       "      <td>[labour, constituency, race, row, labour, choi...</td>\n",
       "      <td>[ORG, CARDINAL, GPE, PERSON, GPE, GPE, CARDINA...</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>Melzer shocks Agassi in San Jose\\n\\nSecond see...</td>\n",
       "      <td>4</td>\n",
       "      <td>sport</td>\n",
       "      <td>[melzer, shock, agassi, san, jose, second, see...</td>\n",
       "      <td>[ORG, PERSON, GPE, ORDINAL, PERSON, PERSON, EV...</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>Wright-Phillips to start on right\\n\\nEngland c...</td>\n",
       "      <td>4</td>\n",
       "      <td>sport</td>\n",
       "      <td>[wright, phillips, start, right, england, coac...</td>\n",
       "      <td>[PERSON, NORP, ORG, PERSON, GPE, ORG, ORDINAL,...</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Making your office work for you\\n\\nOur mission...</td>\n",
       "      <td>0</td>\n",
       "      <td>business</td>\n",
       "      <td>[make, office, work, mission, brighten, work, ...</td>\n",
       "      <td>[DATE, DATE, ORG, GPE, TIME, PERSON, ORG, CARD...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  label  label_en  \\\n",
       "975   Royal couple watch nation's mood\\n\\nPrince Cha...      2  politics   \n",
       "1273  Labour in constituency race row\\n\\nLabour's ch...      2  politics   \n",
       "2222  Melzer shocks Agassi in San Jose\\n\\nSecond see...      4     sport   \n",
       "1797  Wright-Phillips to start on right\\n\\nEngland c...      4     sport   \n",
       "362   Making your office work for you\\n\\nOur mission...      0  business   \n",
       "\n",
       "                                           tokenization  \\\n",
       "975   [royal, couple, watch, nation, mood, prince, c...   \n",
       "1273  [labour, constituency, race, row, labour, choi...   \n",
       "2222  [melzer, shock, agassi, san, jose, second, see...   \n",
       "1797  [wright, phillips, start, right, england, coac...   \n",
       "362   [make, office, work, mission, brighten, work, ...   \n",
       "\n",
       "                                                    ner  PERSON  ORG  DATE  \\\n",
       "975   [ORG, DATE, PERSON, ORG, FAC, ORG, CARDINAL, C...      25    8     8   \n",
       "1273  [ORG, CARDINAL, GPE, PERSON, GPE, GPE, CARDINA...       5    9     1   \n",
       "2222  [ORG, PERSON, GPE, ORDINAL, PERSON, PERSON, EV...      13    3     1   \n",
       "1797  [PERSON, NORP, ORG, PERSON, GPE, ORG, ORDINAL,...      13    6     3   \n",
       "362   [DATE, DATE, ORG, GPE, TIME, PERSON, ORG, CARD...       1    3     2   \n",
       "\n",
       "      GPE  CARDINAL  ...  PERCENT  LOC  TIME  WORK_OF_ART  EVENT  PRODUCT  \\\n",
       "975     6         3  ...        3    0     2            0      0        0   \n",
       "1273    5         7  ...        2    0     0            0      1        0   \n",
       "2222    3         7  ...        0    0     0            0      1        0   \n",
       "1797    4         3  ...        0    0     0            1      0        0   \n",
       "362     1         2  ...        0    0     1            0      0        0   \n",
       "\n",
       "      FAC  QUANTITY  LAW  LANGUAGE  \n",
       "975     2         0    0         0  \n",
       "1273    0         0    0         0  \n",
       "2222    0         0    0         0  \n",
       "1797    0         0    0         0  \n",
       "362     0         0    0         0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d145956",
   "metadata": {},
   "source": [
    "## Join tokenized words and change int label to list of a int label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "190a6dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_(x):\n",
    "    \"\"\"\n",
    "    The tokenized words will be joined as input for tf-idf.\n",
    "    \"\"\"\n",
    "    return ' '.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cce85657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the function to tokenizatio column, a new column named tokenization_joined is created\n",
    "#and will be used for TF-IDF algorithm.\n",
    "dataset_final['tokenization_joined'] = dataset_final['tokenization'].map(join_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1699882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_list(x):\n",
    "    \"\"\"\n",
    "    This function return int as list for tagged.\n",
    "    \"\"\"\n",
    "    return [x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96678e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the function to label column, a new column named label_list is created.\n",
    "dataset_final['label_list'] = dataset_final.label.apply(int_to_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861d74f2",
   "metadata": {},
   "source": [
    "## Examine bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70bcb04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_words_gender(x):\n",
    "    \"\"\"\n",
    "    This function check if certain gender is appeared in the tokenization\n",
    "    \"\"\"\n",
    "    if \"woman\" in x or \"female\" in x:\n",
    "        return \"woman\"\n",
    "    elif \"man\" in x or \"male\" in x:\n",
    "        return \"man\"\n",
    "    else:\n",
    "        return \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0eb4d1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the function to tokenization column,a new column named check_words is created.\n",
    "dataset_final['check_words'] = dataset_final['tokenization'].apply(check_words_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f024d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>check_words</th>\n",
       "      <th>man</th>\n",
       "      <th>none</th>\n",
       "      <th>woman</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_en</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <td>22</td>\n",
       "      <td>474</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entertainment</th>\n",
       "      <td>62</td>\n",
       "      <td>265</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>politics</th>\n",
       "      <td>60</td>\n",
       "      <td>326</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sport</th>\n",
       "      <td>80</td>\n",
       "      <td>388</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech</th>\n",
       "      <td>32</td>\n",
       "      <td>344</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              content           \n",
       "check_words       man none woman\n",
       "label_en                        \n",
       "business           22  474    14\n",
       "entertainment      62  265    59\n",
       "politics           60  326    31\n",
       "sport              80  388    43\n",
       "tech               32  344    25"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#analyze the data\n",
    "dataset_final.pivot_table(index=['label_en'],\n",
    "                          columns=['check_words'],\n",
    "                          values=['content'],\n",
    "                          aggfunc=lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49fc983",
   "metadata": {},
   "source": [
    "## Split the dataset into train, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a9877b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#select x and y for train test\n",
    "X = dataset_final.drop(columns=['label','label_en','label_list'])\n",
    "y = dataset_final[['label','label_list']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2507e5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=1 - train_ratio)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4739e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the X with y again for feature engineering and other purposes\n",
    "X_train_df = x_train.reset_index().merge(y_train.reset_index(),on=['index'])\n",
    "X_val_df = x_val.reset_index().merge(y_val.reset_index(),on=['index'])\n",
    "X_test_df = x_test.reset_index().merge(y_test.reset_index(),on=['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61d8b3d",
   "metadata": {},
   "source": [
    "# Tf-Idf(term frequency - inverse document frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bc6fcc",
   "metadata": {},
   "source": [
    "## test max features on validaiton test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5827640",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max features list for testing\n",
    "tfidf_max_features = [400,800,1000,2000,4000,8000,10000,12000,14000,18000,20000,40000,60000,80000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7128de",
   "metadata": {},
   "source": [
    "Below code cell is commented out because it takes time to compute.\n",
    "Remove comment mark if execution is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd98c92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor feature_num in tfidf_max_features:\\n    \\n    tfidf_vec = TfidfVectorizer(ngram_range=(1,2), \\n                                max_features=feature_num,\\n                               lowercase=False)\\n    X_tfidf = tfidf_vec.fit_transform(X_train_df[\\'tokenization_joined\\'])\\n    X_val_tfidf = tfidf_vec.transform(X_val_df[\\'tokenization_joined\\'])\\n    \\n    xgb_multi_class = XGBClassifier()\\n    xgb_multi_class.fit(X_tfidf,X_train_df[\\'label\\'])\\n    \\n    y_pred = xgb_multi_class.predict(X_val_tfidf)\\n    y_test = X_val_df[\\'label\\']\\n\\n    score = precision_score(y_test,y_pred,average=\\'macro\\')\\n    print(\"max feature is:{0}, macro averaged precision is:{1}\".format(feature_num,score))\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test max_features parameter using XGBoost classification algorithm\n",
    "\"\"\"\n",
    "for feature_num in tfidf_max_features:\n",
    "    \n",
    "    tfidf_vec = TfidfVectorizer(ngram_range=(1,2), \n",
    "                                max_features=feature_num,\n",
    "                               lowercase=False)\n",
    "    X_tfidf = tfidf_vec.fit_transform(X_train_df['tokenization_joined'])\n",
    "    X_val_tfidf = tfidf_vec.transform(X_val_df['tokenization_joined'])\n",
    "    \n",
    "    xgb_multi_class = XGBClassifier()\n",
    "    xgb_multi_class.fit(X_tfidf,X_train_df['label'])\n",
    "    \n",
    "    y_pred = xgb_multi_class.predict(X_val_tfidf)\n",
    "    y_test = X_val_df['label']\n",
    "\n",
    "    score = precision_score(y_test,y_pred,average='macro')\n",
    "    print(\"max feature is:{0}, macro averaged precision is:{1}\".format(feature_num,score))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e449833",
   "metadata": {},
   "source": [
    "### train tfidf vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7288d4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an instance\n",
    "tfidf_vec = TfidfVectorizer(ngram_range=(1,2),\n",
    "                            max_features=20000,\n",
    "                           lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7af2874",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fit and transform training/validation/test sets\n",
    "X_tfidf = tfidf_vec.fit_transform(X_train_df['tokenization_joined'])\n",
    "X_val_tfidf = tfidf_vec.transform(X_val_df['tokenization_joined'])\n",
    "X_test_tfidf = tfidf_vec.transform(X_test_df['tokenization_joined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56a8f510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1668, 20000) (334, 20000) (223, 20000)\n"
     ]
    }
   ],
   "source": [
    "print(X_tfidf.shape,X_val_tfidf.shape,X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378d6254",
   "metadata": {},
   "source": [
    "# Paragraph Embedding - doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "943b04f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc77ea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that transforms data to taggeddcoument format\n",
    "def tag_(x):\n",
    "    return TaggedDocument(words = x['tokenization'],\n",
    "                          tags = x['label_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0a628d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to train/val/test datasets\n",
    "X_train_df['tagged'] = X_train_df[['tokenization','label_list']].apply(tag_,axis=1)\n",
    "#X_val_df['tagged'] = X_val_df[['tokenization','label_list']].apply(tag_,axis=1)\n",
    "#X_test_df['tagged'] = X_test_df[['tokenization','label_list']].apply(tag_,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5787d8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function for traning a doc2vec model\n",
    "def train_doc2vec_model(x, vector_size_):\n",
    "    #create an instance of Doc2Vec\n",
    "    doc2vec = Doc2Vec(vector_size = vector_size_)\n",
    "    #Using training data(x) to build vocabulary\n",
    "    doc2vec.build_vocab(x)\n",
    "    #train the model\n",
    "    doc2vec.train(x,\n",
    "                     total_examples = doc2vec.corpus_count,\n",
    "                     epochs = doc2vec.epochs)\n",
    "    return doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a37fc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to use model to infer_vector and return vector lists\n",
    "def vec_for_learning(model, tagged_docs):\n",
    "    try:\n",
    "        sents = tagged_docs.values\n",
    "        regressors = [model.infer_vector(doc.words) for doc in sents]\n",
    "    except:\n",
    "        regressors = [model.infer_vector(doc) for doc in sents]\n",
    "    return regressors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474d6ee0",
   "metadata": {},
   "source": [
    "## testing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "29f89257",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = [10, 20, 50, 70, 100, 150, 200, 250, 300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb75a101",
   "metadata": {},
   "source": [
    "**Below code cell is <span style=\"color: red;\">commented out</span> because it takes time to compute.\n",
    "<span style=\"color: red;\">Remove comment mark\"\"\" \"\"\"</span> if execution is needed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2f697dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor vector_size_ in vector_size:\\n    \\n    doc2vec_model_test = train_doc2vec_model(X_train_df[\\'tagged\\'],vector_size_)\\n\\n    X_train_vec = vec_for_learning(doc2vec_model_test, X_train_df[\\'tagged\\'])\\n    X_val_vec = vec_for_learning(doc2vec_model_test, X_val_df[\\'tokenization\\'])\\n    \\n    xgb_multi_class = XGBClassifier()\\n    xgb_multi_class.fit(X_train_vec,X_train_df[\\'label\\'])\\n\\n    y_pred = xgb_multi_class.predict(X_val_vec)\\n    y_test = X_val_df[\\'label\\']\\n    \\n    score = precision_score(y_test,y_pred,average=\\'macro\\')\\n    \\n    print(\"vector_size is:{0}, macro averaged precision is:{1}\".format(vector_size_,score))\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "for vector_size_ in vector_size:\n",
    "    \n",
    "    doc2vec_model_test = train_doc2vec_model(X_train_df['tagged'],vector_size_)\n",
    "\n",
    "    X_train_vec = vec_for_learning(doc2vec_model_test, X_train_df['tagged'])\n",
    "    X_val_vec = vec_for_learning(doc2vec_model_test, X_val_df['tokenization'])\n",
    "    \n",
    "    xgb_multi_class = XGBClassifier()\n",
    "    xgb_multi_class.fit(X_train_vec,X_train_df['label'])\n",
    "\n",
    "    y_pred = xgb_multi_class.predict(X_val_vec)\n",
    "    y_test = X_val_df['label']\n",
    "    \n",
    "    score = precision_score(y_test,y_pred,average='macro')\n",
    "    \n",
    "    print(\"vector_size is:{0}, macro averaged precision is:{1}\".format(vector_size_,score))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde70e2b",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d69a6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the mode using training set\n",
    "doc2vec_model = train_doc2vec_model(X_train_df['tagged'],20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e204e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform infer_vector for every dataset\n",
    "X_train_vec = vec_for_learning(doc2vec_model, X_train_df['tagged'])\n",
    "X_val_vec = vec_for_learning(doc2vec_model, X_val_df['tokenization'])\n",
    "X_test_vec = vec_for_learning(doc2vec_model, X_test_df['tokenization'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bafcc7",
   "metadata": {},
   "source": [
    "# combine features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "721a018e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#select NER features for all sets and combine all features\n",
    "X_train_ner = X_train_df[['PERSON', 'ORG', 'DATE', 'GPE','CARDINAL', 'NORP', 'MONEY', 'ORDINAL', 'PERCENT', \n",
    "                          'LOC', 'TIME','EVENT', 'WORK_OF_ART', 'PRODUCT', 'FAC', 'QUANTITY', 'LAW', 'LANGUAGE']]\n",
    "\n",
    "X_train_final = np.hstack((X_tfidf.toarray(),X_train_vec,X_train_ner))\n",
    "\n",
    "\n",
    "X_val_ner = X_val_df[['PERSON', 'ORG', 'DATE', 'GPE','CARDINAL', 'NORP', 'MONEY', 'ORDINAL', 'PERCENT', \n",
    "                      'LOC', 'TIME','EVENT', 'WORK_OF_ART', 'PRODUCT', 'FAC', 'QUANTITY', 'LAW', 'LANGUAGE']]\n",
    "\n",
    "X_val_final = np.hstack((X_val_tfidf.toarray(),X_val_vec,X_val_ner))\n",
    "\n",
    "\n",
    "X_test_ner = X_test_df[['PERSON', 'ORG', 'DATE', 'GPE','CARDINAL', 'NORP', 'MONEY', 'ORDINAL', 'PERCENT', \n",
    "                        'LOC', 'TIME','EVENT', 'WORK_OF_ART', 'PRODUCT', 'FAC', 'QUANTITY', 'LAW', 'LANGUAGE']]\n",
    "\n",
    "X_test_final = np.hstack((X_test_tfidf.toarray(),X_test_vec,X_test_ner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5068ab5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1668, 20038) (334, 20038) (223, 20038)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_final.shape,X_val_final.shape,X_test_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784cef71",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae23e8f8",
   "metadata": {},
   "source": [
    "## f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d979288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "22e8849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_num = [1000,2000,3000,4000,5000,6000,7000,8000,9000,10000,11000,12000,13000,\n",
    "         14000,15000,16000,17000,18000,20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "357b1041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1668, 20038), (1668,))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_final.shape,X_train_df['label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d20ed1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((334, 20038), (334,))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_final.shape,X_val_df['label'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692a60b5",
   "metadata": {},
   "source": [
    "**Below code cell is <span style=\"color: red;\">commented out</span> because it takes time to compute.\n",
    "<span style=\"color: red;\">Remove comment mark\"\"\" \"\"\"</span> if execution is needed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "603aa1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# test k number parameter on training set and validation set\\nfor num in k_num:\\n    fs_ = SelectKBest(f_classif,k=num).fit(X_train_final,X_train_df[\\'label\\'])\\n    \\n    X_train_final_new = fs_.transform(X_train_final)\\n    \\n    xgb_multi_class = XGBClassifier()\\n    xgb_multi_class.fit(X_train_final_new,X_train_df[\\'label\\'])\\n    \\n    X_val_final_new = fs_.transform(X_val_final)\\n    \\n    y_pred = xgb_multi_class.predict(X_val_final_new)\\n    y_test = X_val_df[\\'label\\']\\n    \\n    score = precision_score(y_test,y_pred,average=\\'macro\\')\\n    \\n    print(\"K number is:{0}, macro averaged precision is:{1}\".format(num,score))\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# test k number parameter on training set and validation set\n",
    "for num in k_num:\n",
    "    fs_ = SelectKBest(f_classif,k=num).fit(X_train_final,X_train_df['label'])\n",
    "    \n",
    "    X_train_final_new = fs_.transform(X_train_final)\n",
    "    \n",
    "    xgb_multi_class = XGBClassifier()\n",
    "    xgb_multi_class.fit(X_train_final_new,X_train_df['label'])\n",
    "    \n",
    "    X_val_final_new = fs_.transform(X_val_final)\n",
    "    \n",
    "    y_pred = xgb_multi_class.predict(X_val_final_new)\n",
    "    y_test = X_val_df['label']\n",
    "    \n",
    "    score = precision_score(y_test,y_pred,average='macro')\n",
    "    \n",
    "    print(\"K number is:{0}, macro averaged precision is:{1}\".format(num,score))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6fba238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select use f_classif function,which is ANOVA F-value because the features contain negative number.\n",
    "#fit the data using X_train\n",
    "fs_ = SelectKBest(f_classif,k=3000).fit(X_train_final,X_train_df['label'])\n",
    "#Transform the training/validation/testing data\n",
    "X_train_final_new = fs_.transform(X_train_final)\n",
    "X_val_final_new = fs_.transform(X_val_final)\n",
    "X_test_final_new = fs_.transform(X_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535765f1",
   "metadata": {},
   "source": [
    "# Train and test model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b5283f",
   "metadata": {},
   "source": [
    "## GridSearch best set hyperparameters\n",
    "**Below code cell is <span style=\"color: red;\">commented out</span> because it takes time to compute.\n",
    "<span style=\"color: red;\">Remove comment mark\"\"\" \"\"\"</span> if execution is needed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e3c303af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nparam_grid = {\\n    \\'max_depth\\': [3, 5, 7],\\n    \\'learning_rate\\': [0.1, 0.01, 0.001],\\n    \\'subsample\\': [0.5, 0.7, 1]\\n}\\n\\n# Create the XGBoost model instance\\nxgb_model = XGBClassifier()\\n\\n# Create the GridSearchCV instance\\ngrid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring=\\'accuracy\\')\\n\\n# Fit the GridSearchCV object to the training data\\ngrid_search.fit(X_train_final_new, X_train_df[\\'label\\'])\\n\\n# Print the best set of hyperparameters and the corresponding score\\nprint(\"Best set of hyperparameters: \", grid_search.best_params_)\\nprint(\"Best score: \", grid_search.best_score_)\\n\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'subsample': [0.5, 0.7, 1]\n",
    "}\n",
    "\n",
    "# Create the XGBoost model instance\n",
    "xgb_model = XGBClassifier()\n",
    "\n",
    "# Create the GridSearchCV instance\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train_final_new, X_train_df['label'])\n",
    "\n",
    "# Print the best set of hyperparameters and the corresponding score\n",
    "print(\"Best set of hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6a9813",
   "metadata": {},
   "source": [
    "## Train XGBClassifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "82e86c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an instance of XGBClassifier\n",
    "xgb_multi_class = XGBClassifier(learning_rate = 0.1,max_depth=3,subsample=0.5)\n",
    "\n",
    "#Fit new train data and corresponded label\n",
    "xgb_multi_class.fit(X_train_final_new, X_train_df['label'])\n",
    "\n",
    "#predict on test set\n",
    "y_pred = xgb_multi_class.predict(X_test_final_new)\n",
    "\n",
    "#y true\n",
    "y_test = X_test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ceb448c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92        57\n",
      "           1       0.94      0.98      0.96        45\n",
      "           2       0.95      0.93      0.94        41\n",
      "           3       0.97      0.88      0.92        34\n",
      "           4       1.00      0.96      0.98        46\n",
      "\n",
      "    accuracy                           0.94       223\n",
      "   macro avg       0.95      0.94      0.94       223\n",
      "weighted avg       0.94      0.94      0.94       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "full_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(full_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52efdcd0",
   "metadata": {},
   "source": [
    "# K-Fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "39761ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct a new X(contains features) and y(contains labels)\n",
    "X_kfold = dataset_final.drop(columns=['label','label_en'])\n",
    "y_kfold = dataset_final[['label','label_list']]\n",
    "\n",
    "#create an instance of KFold and assign n_splits = 5,meaning there will be five fold cross-validation.\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "#create four variables that will hold the results the cross-validation outputs\n",
    "avg_accuracy = 0\n",
    "macro_avg_precision = 0\n",
    "macro_avg_recall = 0\n",
    "macro_avg_f1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af97d048",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/md/3m3pgbq106ddq_n9t9thhs5m0000gn/T/ipykernel_56826/243748759.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_new['tagged'] = X_train_new[['tokenization','label_list']].apply(tag_,axis=1)\n",
      "/var/folders/md/3m3pgbq106ddq_n9t9thhs5m0000gn/T/ipykernel_56826/243748759.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_new['tagged'] = X_train_new[['tokenization','label_list']].apply(tag_,axis=1)\n",
      "/var/folders/md/3m3pgbq106ddq_n9t9thhs5m0000gn/T/ipykernel_56826/243748759.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_new['tagged'] = X_train_new[['tokenization','label_list']].apply(tag_,axis=1)\n",
      "/var/folders/md/3m3pgbq106ddq_n9t9thhs5m0000gn/T/ipykernel_56826/243748759.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_new['tagged'] = X_train_new[['tokenization','label_list']].apply(tag_,axis=1)\n",
      "/var/folders/md/3m3pgbq106ddq_n9t9thhs5m0000gn/T/ipykernel_56826/243748759.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_new['tagged'] = X_train_new[['tokenization','label_list']].apply(tag_,axis=1)\n"
     ]
    }
   ],
   "source": [
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    \n",
    "    \"\"\"\n",
    "    split the data into train and test subsets\n",
    "    \"\"\"\n",
    "    X_train_new, X_test_new = X_kfold.iloc[train_index] , X_kfold.iloc[test_index]\n",
    "    y_train_new, y_test_new = y_kfold.iloc[train_index] , y_kfold.iloc[test_index]\n",
    "    \n",
    "    \"\"\"\n",
    "    train tf-idf feature\n",
    "    \"\"\"\n",
    "    # create TfidfVectorizer\n",
    "    tfidf_vec_kf = TfidfVectorizer(ngram_range=(1,2),max_features=20000,lowercase=False)\n",
    "    #fit and transform X_train\n",
    "    X_train_tfidf_kf = tfidf_vec_kf.fit_transform(X_train_new['tokenization_joined'])\n",
    "    #transform X_test\n",
    "    X_test_tfidf_kf = tfidf_vec_kf.transform(X_test_new['tokenization_joined'])\n",
    "    \n",
    "    \"\"\"\n",
    "    train doc2vec feature\n",
    "    \"\"\"\n",
    "    X_train_new['tagged'] = X_train_new[['tokenization','label_list']].apply(tag_,axis=1)\n",
    "    \n",
    "    model_test = Doc2Vec(vector_size=20)\n",
    "    #build vocabulary\n",
    "    model_test.build_vocab(X_train_new['tagged'])\n",
    "    #train the model\n",
    "    model_test.train(X_train_new['tagged'],\n",
    "                     total_examples = model_test.corpus_count,\n",
    "                     epochs = model_test.epochs)\n",
    "    #infer the vector for train and test datasets\n",
    "    X_train_vec_kf = vec_for_learning(model_test, X_train_new['tagged'])\n",
    "    X_test_vec_kf = vec_for_learning(model_test, X_test_new['tokenization'])\n",
    "    \n",
    "    \"\"\"\n",
    "    select NER feature\n",
    "    \"\"\"\n",
    "    columns = ['PERSON', 'ORG', 'DATE', 'GPE','CARDINAL', 'NORP', 'MONEY', 'ORDINAL', 'PERCENT', 'LOC', 'TIME','EVENT', \n",
    "                'WORK_OF_ART', 'PRODUCT', 'FAC', 'QUANTITY', 'LAW', 'LANGUAGE']\n",
    "    X_train_ner_kf = X_train_new[columns]\n",
    "    X_test_ner_kf = X_test_new[columns]\n",
    "    \n",
    "    \"\"\"\n",
    "    combine features\n",
    "    \"\"\"\n",
    "    X_train_final_kf = np.hstack((X_train_tfidf_kf.toarray(),X_train_vec_kf,X_train_ner_kf))\n",
    "    X_test_final_kf = np.hstack((X_test_tfidf_kf.toarray(),X_test_vec_kf,X_test_ner_kf))\n",
    "    \n",
    "    \"\"\"\n",
    "    feature selection\n",
    "    \"\"\"\n",
    "    \n",
    "    fs_kf = SelectKBest(f_classif,k=3000).fit(X_train_final_kf,y_train_new['label'])\n",
    "    X_train_final_new_kf = fs_kf.transform(X_train_final_kf)\n",
    "    X_test_final_new_kf = fs_kf.transform(X_test_final_kf)\n",
    "    \n",
    "    \"\"\"\n",
    "    train the model\n",
    "    \"\"\"\n",
    "    xgb_multi_class = XGBClassifier(learning_rate = 0.1,max_depth = 3,subsample = 0.5)\n",
    "    xgb_multi_class.fit(X_train_final_new_kf, y_train_new['label'])\n",
    "    \n",
    "    \"\"\"\n",
    "    predict \n",
    "    \"\"\"\n",
    "    \n",
    "    y_pred_kf = xgb_multi_class.predict(X_test_final_new_kf)\n",
    "    y_test_kf = y_test_new['label']\n",
    "    \n",
    "    \"\"\"\n",
    "    accumulate results\n",
    "    \"\"\"\n",
    "    avg_accuracy  += accuracy_score(y_test_kf, y_pred_kf)\n",
    "    macro_avg_precision += precision_score(y_test_kf, y_pred_kf,average='macro')\n",
    "    macro_avg_recall += recall_score(y_test_kf, y_pred_kf,average='macro')\n",
    "    macro_avg_f1 += f1_score(y_test_kf, y_pred_kf,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7610097a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg accuracy is: 0.9608988764044943\n",
      "macro avg precision is: 0.9600561379206676\n",
      "macro avg recall is: 0.9610578007471011\n",
      "macro avg f1 is: 0.9603562922634108\n"
     ]
    }
   ],
   "source": [
    "print(\"avg accuracy is:\",avg_accuracy/5)\n",
    "print(\"macro avg precision is:\",macro_avg_precision/5)\n",
    "print(\"macro avg recall is:\",macro_avg_recall/5)\n",
    "print(\"macro avg f1 is:\",macro_avg_f1/5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
